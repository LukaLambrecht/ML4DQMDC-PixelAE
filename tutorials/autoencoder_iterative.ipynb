{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test an autoencoder iteratively on local datasets\n",
    "\n",
    "This notebook investigates the possibility to perform local autoencoder training, i.e. training on a small number of runs instead of training on a large dataset (e.g. a full year of data taking).  \n",
    "This notebook consists of three parts:\n",
    "   - Reading and preparing the data (common to part 2 and 3) \n",
    "   - Train an autoencoder on the first 5, 10, 15 etc. runs of 2017 data taking.  \n",
    "   - Choose a random run to test on, use 5 previous runs for training. This is a first step naive attempt towards using dedicated reference runs for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Reading and preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### imports\n",
    "\n",
    "# external modules\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# local modules\n",
    "sys.path.append('../utils')\n",
    "import dataframe_utils as dfu\n",
    "import hist_utils as hu\n",
    "import plot_utils as pu\n",
    "import autoencoder_utils as aeu\n",
    "import generate_data_utils as gdu\n",
    "sys.path.append('../src')\n",
    "import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read the data and perform some selections\n",
    "# note: this cell assumes you have a csv file stored at the specified location,\n",
    "#       containing only histograms of the specified type;\n",
    "#       see the tutorial read_and_write_data for examples on how to create such files!\n",
    "\n",
    "histname = 'chargeInner_PXLayer_2'\n",
    "filename = 'DF2017_'+histname+'.csv'\n",
    "datadir = '../data'\n",
    "\n",
    "dloader = DataLoader.DataLoader()\n",
    "df = dloader.get_dataframe_from_file( os.path.join(datadir, filename) )\n",
    "print('raw input data shape: {}'.format( dfu.get_hist_values(df)[0].shape ))\n",
    "df = dfu.select_dcson(df)\n",
    "df = dfu.select_highstat(df)\n",
    "print('number of passing lumisections after selection: {}'.format( len(df) ))\n",
    "runs_all = dfu.get_runs(df)\n",
    "(hists_all,runnbs_all,lsnbs_all) = hu.preparedatafromdf(df,returnrunls=True,rebinningfactor=1,donormalize=True)\n",
    "print('shape of histogram array: {}'.format(hists_all.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Updating the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get a test set\n",
    "\n",
    "goodrunsls = {'2017':\n",
    "              {\n",
    "                \"297056\":[[-1]],\n",
    "              }}\n",
    "\n",
    "badrunsls = {'2017':\n",
    "            {\n",
    "                \"297287\":[[-1]],\n",
    "                \"297288\":[[-1]],\n",
    "                \"297289\":[[-1]],\n",
    "                \"299316\":[[-1]],\n",
    "                \"299324\":[[-1]],\n",
    "            }}\n",
    "\n",
    "# select the correct data-taking year relevant for the file chosen above\n",
    "year = '2017'\n",
    "\n",
    "# load good and bad sets from df\n",
    "(hists_good,runnbs_good,lsnbs_good) = hu.preparedatafromdf( \n",
    "                                        dfu.select_runsls(df,goodrunsls[year]),\n",
    "                                        returnrunls=True, donormalize=True)\n",
    "(hists_bad,runnbs_bad,lsnbs_bad) = hu.preparedatafromdf( \n",
    "                                        dfu.select_runsls(df,badrunsls[year]),\n",
    "                                        returnrunls=True, donormalize=True)\n",
    "print('shape of good test set '+str(hists_good.shape))\n",
    "print('shape of bad test set '+str(hists_bad.shape))\n",
    "\n",
    "# make plot\n",
    "pu.plot_sets([hists_good,hists_bad],\n",
    "             colorlist=['b','r'],\n",
    "             labellist=['good','bad'],\n",
    "             transparencylist=[],\n",
    "             xlims=(0,-1))\n",
    "\n",
    "# use resampling tool to upsample and add more variation\n",
    "(hists_good,_,_) = gdu.upsample_hist_set(hists_good,ntarget=2e3,fourierstdfactor=15., doplot=False)\n",
    "(hists_bad,_,_) = gdu.upsample_hist_set(hists_bad,ntarget=2e3,fourierstdfactor=5., doplot=False)\n",
    "print('shape of good test set '+str(hists_good.shape))\n",
    "print('shape of bad test set '+str(hists_bad.shape))\n",
    "# make plot\n",
    "\n",
    "pu.plot_sets([hists_good,hists_bad],\n",
    "             colorlist=['b','r'],\n",
    "             labellist=['good','bad'],\n",
    "             transparencylist=[0.1,0.1],\n",
    "             xlims=(0,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### function to purify training set by removing a given fraction of high mse histograms\n",
    "\n",
    "def purify_training_set(hists,model,rmfraction):\n",
    "    mse = aeu.mseTop10Raw(hists,model.predict(hists))\n",
    "    threshold = np.quantile(mse,1-rmfraction)\n",
    "    keepindices = np.where(mse<threshold)\n",
    "    return hists[keepindices]\n",
    "\n",
    "### functions to test performance on test set\n",
    "\n",
    "def test_autoencoder(hists_good,hists_bad,model):\n",
    "    mse_good = aeu.mseTop10Raw(hists_good,model.predict(hists_good))\n",
    "    mse_bad = aeu.mseTop10Raw(hists_bad,model.predict(hists_bad))\n",
    "    labels_good = np.zeros(len(mse_good))\n",
    "    labels_bad = np.ones(len(mse_bad))\n",
    "\n",
    "    labels = np.concatenate(tuple([labels_good,labels_bad]))\n",
    "    scores = np.concatenate(tuple([mse_good,mse_bad]))\n",
    "    maxnoninf = np.max(np.where(scores==np.inf,np.min(scores),scores))\n",
    "    scores = np.where(scores==np.inf,maxnoninf,scores)\n",
    "\n",
    "    auc = aeu.get_roc(scores, labels, mode='full', bootstrap_samples=100)\n",
    "    plt.show()\n",
    "\n",
    "def plot_examples(hists_good,hists_bad,model):\n",
    "    # set parameters\n",
    "    nexamples = 6\n",
    "    fig,axs = plt.subplots(2,nexamples,figsize=(24,12))\n",
    "    inds_good = np.random.choice(range(len(hists_good)),nexamples)\n",
    "    inds_bad = np.random.choice(range(len(hists_bad)),nexamples)\n",
    "    inds_ref = np.random.choice(range(len(hists_good)),20)\n",
    "    # determine whether to show run/lumi number in label (not possible when using resampled sets)\n",
    "    truelabel = True\n",
    "    if( len(hists_good)!=len(runnbs_good) or len(hists_bad)!=len(runnbs_good) ): truelabel = False\n",
    "    # plot examples\n",
    "    for i in range(nexamples):\n",
    "        hist_good = hists_good[inds_good[i]:inds_good[i]+1]\n",
    "        reco_good = model.predict(hist_good)\n",
    "        hist_bad = hists_bad[inds_bad[i]:inds_bad[i]+1]\n",
    "        reco_bad = model.predict(hist_bad)\n",
    "        hist_good_label = hist_bad_label = 'hist'\n",
    "        if truelabel: \n",
    "            hist_good_label += ' (run: '+str(int(runnbs_good[inds_good[i]]))+', ls: '+str(int(lsnbs_good[inds_good[i]]))+')'\n",
    "            hist_bad_label += ' (run: '+str(int(runnbs_bad[inds_bad[i]]))+', ls: '+str(int(lsnbs_bad[inds_bad[i]]))+')'\n",
    "        pu.plot_sets([hist_good,reco_good,hists_good[inds_ref]],\n",
    "                  fig=fig,ax=axs[0,i],\n",
    "                  title='',\n",
    "                  colorlist=['black','red','blue'],\n",
    "                  labellist=[hist_good_label,'reco','good hists'],\n",
    "                  transparencylist=[1.,1.,0.1])\n",
    "        pu.plot_sets([hist_bad,reco_bad,hists_good[inds_ref]],\n",
    "                  fig=fig,ax=axs[1,i],\n",
    "                  title='',\n",
    "                  colorlist=['black','red','blue'],\n",
    "                  labellist=[hist_bad_label,'reco','good hists'],\n",
    "                  transparencylist=[1.,1.,0.1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### iterate over growing amount of data\n",
    "\n",
    "nruns = [5,10]\n",
    "\n",
    "# first iteration manually\n",
    "X_train = hists_all[np.where(runnbs_all<runs_all[nruns[0]])]\n",
    "print('size of training set (intial): '+str(len(X_train)))\n",
    "(X_train_ext,_,_) = gdu.upsample_hist_set(X_train, 1e5)\n",
    "#X_train_ext = X_train\n",
    "model = aeu.train_simple_autoencoder(X_train_ext,nepochs=10)\n",
    "print('evaluating model on test set')\n",
    "test_autoencoder(hists_good,hists_bad,model)\n",
    "plot_examples(hists_good,hists_bad,model)\n",
    "\n",
    "# next iterations in a loop\n",
    "for i in range(1,len(nruns)):\n",
    "    \n",
    "    this_upperbound = runs_all[nruns[i]]\n",
    "    this_lowerbound = runs_all[nruns[i-1]]\n",
    "    print('adding runs {} to {}'.format(this_lowerbound,this_upperbound))\n",
    "    print('(training on {} runs in total)'.format(nruns[i]))\n",
    "    newhists = hists_all[np.where( (runnbs_all<this_upperbound) & (runnbs_all>=this_lowerbound) )]\n",
    "    print('number of new histograms added to training set: '+str(len(newhists)))\n",
    "    X_train = np.concatenate( (X_train,newhists), axis=0 )\n",
    "    X_train = purify_training_set(X_train,model,0.1)\n",
    "    print('size of training set (intial): '+str(len(X_train)))\n",
    "    (X_train_ext,_,_) = gdu.upsample_hist_set(X_train, 1e5)\n",
    "    #X_train_ext = X_train\n",
    "    model = aeu.train_simple_autoencoder(X_train_ext)\n",
    "    print('size of training set (after training and purifying): '+str(len(X_train)))\n",
    "    print('evaluating model on test set')\n",
    "    test_autoencoder(hists_good,hists_bad,model)\n",
    "    plot_examples(hists_good,hists_bad,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Local training on nearby runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### choose random run for testing, train on previous runs\n",
    "# (testing: see next cell)\n",
    "\n",
    "# choose runs\n",
    "print('number of available runs: '+str(len(runs_all)))\n",
    "runindex = np.random.choice(range(5,len(runs_all)))\n",
    "#runindex = runs_all.index(305364)\n",
    "test_run = runs_all[runindex]\n",
    "print('chosen run index: '+str(runindex)+', corresponding to run: '+str(test_run))\n",
    "training_runs = runs_all[runindex-5:runindex]\n",
    "print('runs used for training: '+str(training_runs))\n",
    "\n",
    "# get the data\n",
    "df = dfu.select_dcson(df)\n",
    "(hists_train,runnbs_train,lsnbs_train) = hu.preparedatafromdf( dfu.select_runs(df,training_runs),returnrunls=True,donormalize=True)\n",
    "(hists_test,runnbs_test,lsnbs_test) = hu.preparedatafromdf( dfu.select_runs(df,[test_run]),returnrunls=True,donormalize=True)\n",
    "print('shape of training set '+str(hists_train.shape))\n",
    "print('shape of test set '+str(hists_test.shape))\n",
    "# make plot\n",
    "pu.plot_sets([hists_train,hists_test],ax=None,title='',colorlist=['b','g'],labellist=['train','test'],transparencylist=[0.5,0.5],xlims=(0,-1))\n",
    "plt.show()\n",
    "\n",
    "# train the autoencoder\n",
    "(X_train,_,_) = gdu.upsample_hist_set(hists_train, 1e5)\n",
    "#X_train = hists_train\n",
    "model = aeu.train_simple_autoencoder(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test the autoencoder trained in the previous cell\n",
    "\n",
    "# note: do not simply use hists_good for a good test set, \n",
    "# as the model might not be trained on all shape variations that are supposed to be 'good',\n",
    "# resulting in artificially bad performance.\n",
    "# we can use hists_test instead, but it is not at all guaranteed that all of them are good.\n",
    "# hence the label 'good hists' in the plot below is not necessarily correct.\n",
    "\n",
    "test_autoencoder(hists_test,hists_bad,model)\n",
    "plot_examples(hists_test,hists_bad,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
