{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "solar-ceramic",
   "metadata": {},
   "source": [
    "## Two-dimensional histogram classification based on the max bin-per-bin pull with respect to a reference histogram\n",
    "\n",
    "This notebook investigates a very simple classifier, that just looks at the maximum bin-per-bin value difference with respect to a given reference histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-rings",
   "metadata": {},
   "outputs": [],
   "source": [
    "### imports\n",
    "\n",
    "# external modules\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "\n",
    "# local modules\n",
    "sys.path.append('../utils')\n",
    "import dataframe_utils as dfu\n",
    "import plot_utils as pu\n",
    "import hist_utils as hu\n",
    "importlib.reload(dfu)\n",
    "importlib.reload(pu)\n",
    "importlib.reload(hu)\n",
    "sys.path.append('../src')\n",
    "import DataLoader\n",
    "importlib.reload(DataLoader)\n",
    "sys.path.append('../src/classifiers')\n",
    "import MaxPullClassifier\n",
    "importlib.reload(MaxPullClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empirical-camping",
   "metadata": {},
   "source": [
    "### Part 1: First exploration on a small test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-antenna",
   "metadata": {},
   "outputs": [],
   "source": [
    "### load the histogram dataframe\n",
    "\n",
    "histname = 'clusterposition_zphi_ontrack_PXLayer_1'\n",
    "filename = 'DF2017B_'+histname+'_subset.csv'\n",
    "datadir = '../data'\n",
    "\n",
    "dloader = DataLoader.DataLoader()\n",
    "df = dloader.get_dataframe_from_file( os.path.join(datadir, filename) )\n",
    "print('raw input data shape: {}'.format( dfu.get_hist_values(df)[0].shape ))\n",
    "\n",
    "# select DCS-bit on data\n",
    "df = dfu.select_dcson(df)\n",
    "print('number of selected lumisections: '+str(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-quest",
   "metadata": {},
   "outputs": [],
   "source": [
    "### extract the histograms as a numpy array from the dataframe\n",
    "\n",
    "(histograms,runnbs,lsnbs) = dfu.get_hist_values(df)\n",
    "print('shape of histogram array: {}'.format(histograms.shape))\n",
    "print('shape of run number array: {}'.format(runnbs.shape))\n",
    "print('shape of lumisection number array: {}'.format(lsnbs.shape))\n",
    "\n",
    "### further preprocessing of the data (cropping, rebinning, normalizing)\n",
    "\n",
    "histograms = hu.crophists(histograms,[slice(1,-1,None),slice(1,-1,None)]) # remove under- and overflow bins\n",
    "histograms = hu.crophists(histograms,[slice(None,None,None),slice(80,220,None)]) # cut out uninteresting parts\n",
    "histograms = hu.rebinhists(histograms,(5,5))\n",
    "print('shape of histogram array: {}'.format(histograms.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-journalism",
   "metadata": {},
   "outputs": [],
   "source": [
    "### define a reference histogram as the average of the set\n",
    "### and a max pull classifier based on this reference histogram\n",
    "\n",
    "refhist = hu.averagehists( histograms, nout=1 )[0,:,:]\n",
    "print('shape of averaged histogram: {}'.format(refhist.shape))\n",
    "classifier = MaxPullClassifier.MaxPullClassifier()\n",
    "classifier.train( np.array([refhist]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-fifth",
   "metadata": {},
   "outputs": [],
   "source": [
    "### calculate max pull for each histogram\n",
    "\n",
    "maxpulls = classifier.evaluate( histograms )\n",
    "pu.plot_distance(maxpulls)\n",
    "avg,std = pu.plot_distance(maxpulls,doplot=False)\n",
    "print(avg)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finished-looking",
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot examples for histograms with large pulls\n",
    "\n",
    "threshold = avg+3*std\n",
    "\n",
    "for i in range(len(histograms)):\n",
    "    if maxpulls[i] < threshold: continue\n",
    "    histlist = [histograms[i],classifier.refhist,classifier.getpull(histograms[i])]\n",
    "    subtitles = ['test histogram','reference histogram','pull']\n",
    "    pu.plot_hists_2d(histlist, ncols=3, title = None, subtitles=subtitles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-orlando",
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot examples of histograms with small pulls\n",
    "\n",
    "inds = np.argsort(maxpulls)[:3]\n",
    "for i in inds:\n",
    "    histlist = [histograms[i],classifier.refhist,classifier.getpull(histograms[i])]\n",
    "    subtitles = ['test histogram','reference histogram','pull']\n",
    "    pu.plot_hists_2d(histlist, ncols=3, title = None, subtitles=subtitles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-andrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "### investigate a particular lumisection in more detail\n",
    "\n",
    "idx = 0\n",
    "print('run: {}, lumisection: {}'.format(runnbs[idx],lsnbs[idx]))\n",
    "print('maximum pull for this lumisection: {}'.format(maxpulls[idx]))\n",
    "histlist = [histograms[idx],classifier.refhist,classifier.getpull(histograms[idx])]\n",
    "subtitles = ['test histogram','reference histogram','pull']\n",
    "_ = pu.plot_hists_2d( histlist, ncols=3, title = None, subtitles=subtitles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13624a71",
   "metadata": {},
   "source": [
    "### Part 2: Use a locally changing reference histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-illinois",
   "metadata": {},
   "outputs": [],
   "source": [
    "### local approach\n",
    "\n",
    "nprev = 5\n",
    "\n",
    "maxpulls = np.zeros(len(histograms))\n",
    "classifiers = [None]*nprev\n",
    "for i in range(nprev,len(histograms)):\n",
    "    hist = histograms[i]\n",
    "    refhist = hu.averagehists( histograms[i-nprev:i], nout=1 )[0,:,:]\n",
    "    classifier = MaxPullClassifier.MaxPullClassifier()\n",
    "    classifier.train( np.array([refhist]) )\n",
    "    classifiers.append(classifier)\n",
    "    maxpulls[i] = classifier.evaluate( np.array([hist]) )\n",
    "\n",
    "pu.plot_distance(maxpulls)\n",
    "avg,std = pu.plot_distance(maxpulls,doplot=False)\n",
    "plt.show()\n",
    "print('average pull: {}'.format(avg))\n",
    "print('std dev of pulls: {}'.format(std))\n",
    "\n",
    "# make plots of histograms with large local pulls\n",
    "threshold = avg+3*std\n",
    "print('histograms with largest pulls:')\n",
    "for i in range(len(histograms)):\n",
    "    if maxpulls[i] < threshold: continue\n",
    "    histlist = [histograms[i],classifiers[i].refhist,classifiers[i].getpull(histograms[i])]\n",
    "    subtitles = ['test histogram','reference histogram','pull']\n",
    "    title = 'index: {}, run: {}, lumisection: {}, max pull: {}'.format(i, runnbs[i],lsnbs[i],maxpulls[i])\n",
    "    pu.plot_hists_2d(histlist, ncols=3, title = title, subtitles=subtitles)\n",
    "plt.show()\n",
    "\n",
    "# make plots of histograms with small local pulls\n",
    "inds = np.argsort(maxpulls)[nprev:nprev+5]\n",
    "print(inds)\n",
    "print('histograms with smalles pulls:')\n",
    "for i in inds:\n",
    "    histlist = [histograms[i],classifiers[i].refhist,classifiers[i].getpull(histograms[i])]\n",
    "    subtitles = ['test histogram','reference histogram','pull']\n",
    "    title = 'index: {}, run: {}, lumisection: {}, max pull: {}'.format(i, runnbs[i],lsnbs[i],maxpulls[i])\n",
    "    pu.plot_hists_2d(histlist, ncols=3, title = title, subtitles=subtitles)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-honolulu",
   "metadata": {},
   "outputs": [],
   "source": [
    "### investigate a particular lumisection in more detail\n",
    "\n",
    "idx = 136\n",
    "if idx < nprev:\n",
    "    raise Exception('ERROR: cannot plot index {} since classification is done based on {} previous lumisections'.format(idx,nprev))\n",
    "print('run: {}, lumisection: {}'.format(runnbs[idx],lsnbs[idx]))\n",
    "print('maximum pull for this lumisection: {}'.format(maxpulls[idx]))\n",
    "histlist = [histograms[idx],classifiers[idx].refhist,classifiers[idx].getpull(histograms[idx])]\n",
    "subtitles = ['test histogram','reference histogram','pull']\n",
    "print('test histogram, reference histogram and pulls:')\n",
    "_ = pu.plot_hists_2d( histlist, ncols=3, title = None, subtitles=subtitles)\n",
    "plt.show()\n",
    "print('histograms that were averaged to make the reference histograms:')\n",
    "_ = pu.plot_hists_2d( histograms[idx-nprev:idx], ncols=3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fancy-joseph",
   "metadata": {},
   "source": [
    "### Part 3: Load a set of histograms to define a reference, a good test set and a bad test set, and test the discrimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-excuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "### load the histograms\n",
    "\n",
    "histname = 'clusterposition_zphi_ontrack_PXLayer_1'\n",
    "datadir = '../data'\n",
    "dloader = DataLoader.DataLoader()\n",
    "\n",
    "# load the training data and train the classifier\n",
    "filename = dffile = 'DF2017B_'+histname+'_subset.csv'\n",
    "df = dloader.get_dataframe_from_file( os.path.join(datadir, filename) )\n",
    "print('raw input data shape: {}'.format( dfu.get_hist_values(df)[0].shape ))\n",
    "df = dfu.select_dcson(df)\n",
    "(hists_ref) = hu.preparedatafromdf(df, cropslices=[slice(1,-1,None),slice(81,221,None)], rebinningfactor=(2,2), donormalize=False, doplot=False)\n",
    "_ = pu.plot_hists_2d(hists_ref[:4], ncols=4, title='some example histograms for averaging')\n",
    "print('number of lumisections in histogram set for averaging: '+str(len(df)))\n",
    "refhist = hu.averagehists( hists_ref, nout=1 )[0,:,:]\n",
    "_ = pu.plot_hist_2d(refhist, title='averaged histogram (used as reference)')\n",
    "print('shape of averaged histogram: {}'.format(refhist.shape))\n",
    "classifier = MaxPullClassifier.MaxPullClassifier()\n",
    "classifier.train( np.array([refhist]) )\n",
    "\n",
    "# load the good data\n",
    "filename = dffile = 'DF2017B_'+histname+'_run297056.csv'\n",
    "df = dloader.get_dataframe_from_file( os.path.join(datadir, filename) )\n",
    "print('raw input data shape: {}'.format( dfu.get_hist_values(df)[0].shape ))\n",
    "df = dfu.select_dcson(df)\n",
    "(hists_good, runnbs_good, lsnbs_good) = hu.preparedatafromdf(df, returnrunls=True, cropslices=[slice(1,-1,None),slice(81,221,None)], rebinningfactor=(2,2), donormalize=False, doplot=False)\n",
    "_ = pu.plot_hists_2d(hists_good[:4], ncols=4, title='some example histograms in good test set')\n",
    "print('number of lumisections in good test set: '+str(len(df)))\n",
    "\n",
    "# load the bad data\n",
    "filename = dffile = 'DF2017B_'+histname+'_run297169.csv'\n",
    "df = dloader.get_dataframe_from_file( os.path.join(datadir, filename) )\n",
    "print('raw input data shape: {}'.format( dfu.get_hist_values(df)[0].shape ))\n",
    "df = dfu.select_dcson(df)\n",
    "(hists_bad, runnbs_bad, lsnbs_bad) = hu.preparedatafromdf(df, returnrunls=True, cropslices=[slice(1,-1,None),slice(81,221,None)], rebinningfactor=(2,2), donormalize=False, doplot=False)\n",
    "_ = pu.plot_hists_2d(hists_bad[:4], ncols=4, title='some example histograms in bad test set')\n",
    "print('number of lumisections in bad test set: '+str(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-karen",
   "metadata": {},
   "outputs": [],
   "source": [
    "### perform the classification\n",
    "\n",
    "scores_good = classifier.evaluate( hists_good )\n",
    "labels_good = np.zeros(len(scores_good))\n",
    "scores_bad = classifier.evaluate( hists_bad )\n",
    "labels_bad = np.ones(len(scores_bad))\n",
    "scores = np.concatenate((scores_good,scores_bad))\n",
    "labels = np.concatenate((labels_good,labels_bad))\n",
    "_ = pu.plot_score_dist( scores, labels, nbins=50, normalize=True,\n",
    "                        siglabel='Anomalies', sigcolor='r',\n",
    "                        bcklabel='Good histograms', bckcolor='g',\n",
    "                        title='output score distributions for signal and background',\n",
    "                        xaxtitle='output score', yaxtitle=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-tamil",
   "metadata": {},
   "outputs": [],
   "source": [
    "### check some examples\n",
    "\n",
    "nplot = 5\n",
    "\n",
    "inds_good = np.random.choice(np.array(list(range(len(hists_good)))),size=nplot)\n",
    "print('example histograms from good test set:')\n",
    "for i in inds_good:\n",
    "    histlist = [hists_good[i],classifier.refhist,classifier.getpull(hists_good[i])]\n",
    "    subtitles = ['good test histogram','reference histogram','pull']\n",
    "    title = 'index: {}, run: {}, lumisection: {}, max pull: {}'.format(i, runnbs_good[i],lsnbs_good[i],scores_good[i])\n",
    "    pu.plot_hists_2d(histlist, ncols=3, title = title, subtitles=subtitles)\n",
    "plt.show()\n",
    "\n",
    "inds_bad = np.random.choice(np.array(range(len(hists_bad))),size=nplot)\n",
    "print('example histograms from bad test set:')\n",
    "for i in inds_bad:\n",
    "    histlist = [hists_bad[i],classifier.refhist,classifier.getpull(hists_bad[i])]\n",
    "    subtitles = ['bad test histogram','reference histogram','pull']\n",
    "    title = 'index: {}, run: {}, lumisection: {}, max pull: {}'.format(i, runnbs_bad[i],lsnbs_bad[i],scores_bad[i])\n",
    "    pu.plot_hists_2d(histlist, ncols=3, title = title, subtitles=subtitles)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laden-nerve",
   "metadata": {},
   "outputs": [],
   "source": [
    "### re-define the classifier with a nondefault number of maximum pull bins to consider in a loop to determine the optimal value\n",
    "\n",
    "ns = [1,10,20,50,100,500]\n",
    "\n",
    "for n in ns:\n",
    "    \n",
    "    classifier.set_nmaxpulls( n )\n",
    "    scores_good = classifier.evaluate( hists_good )\n",
    "    labels_good = np.zeros(len(scores_good))\n",
    "    scores_bad = classifier.evaluate( hists_bad )\n",
    "    labels_bad = np.ones(len(scores_bad))\n",
    "    scores = np.concatenate((scores_good,scores_bad))\n",
    "    labels = np.concatenate((labels_good,labels_bad))\n",
    "    _ = pu.plot_score_dist( scores, labels, nbins=50, normalize=True,\n",
    "                            siglabel='Anomalies', sigcolor='r',\n",
    "                            bcklabel='Good histograms', bckcolor='g',\n",
    "                            title='output score distributions for signal and background',\n",
    "                            xaxtitle='output score', yaxtitle=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-shore",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74242c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
