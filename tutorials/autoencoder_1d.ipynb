{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test an autoencoder on a set of 1D monitoring elements  \n",
    "\n",
    "This notebook walks you through the basics of the autoencoder approach to detecting anomalies for 1D monitoring elements.  \n",
    "It consists of the following steps:  \n",
    "\n",
    "   - Loading the data  \n",
    "   - Applying selections (e.g. DCS-bit on and sufficient statistics)  \n",
    "   - Preprocessing (e.g. normalizing)  \n",
    "   - Building an autoencoder model with keras  \n",
    "   - Investigate the output  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### imports\n",
    "\n",
    "# external modules\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "\n",
    "# local modules\n",
    "sys.path.append('../utils')\n",
    "import dataframe_utils as dfu\n",
    "import hist_utils as hu\n",
    "import autoencoder_utils as aeu\n",
    "import plot_utils as pu\n",
    "import generate_data_utils as gdu\n",
    "sys.path.append('../src')\n",
    "import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read the data\n",
    "# note: this cell assumes you have a csv file stored at the specified location,\n",
    "#       containing only histograms of the specified type;\n",
    "#       see the tutorial read_and_write_data for examples on how to create such files!\n",
    "\n",
    "histname = 'chargeInner_PXLayer_2'\n",
    "filename = 'DF2017_'+histname+'.csv'\n",
    "datadir = '../data'\n",
    "\n",
    "dloader = DataLoader.DataLoader()\n",
    "df = dloader.get_dataframe_from_file( os.path.join(datadir, filename) )\n",
    "print('raw input data shape: {}'.format( dfu.get_hist_values(df)[0].shape ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### filtering: select only DCS-bit on data and filter out low statistics\n",
    "\n",
    "df = dfu.select_dcson(df)\n",
    "print('number of passing lumisections after DCS selection: {}'.format( len(df) ))\n",
    "\n",
    "df = dfu.select_highstat(df, entries_to_bins_ratio=100)\n",
    "print('number of passing lumisections after high statistics selection: {}'.format( len(df) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### preprocessing of the data: rebinning and normalizing\n",
    "\n",
    "rebinningfactor = 1\n",
    "\n",
    "X_train = hu.preparedatafromdf(df, rebinningfactor=rebinningfactor,\n",
    "                               donormalize=True, doplot=True)\n",
    "(ntrain,nbins) = X_train.shape\n",
    "print('size of training set: '+str(X_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### build the model and train it\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "arch = [int(X_train.shape[1]/2.)]\n",
    "act = ['tanh']*len(arch)\n",
    "opt = 'adam'\n",
    "loss = aeu.mseTop10\n",
    "autoencoder = aeu.getautoencoder(input_size,arch,act,opt,loss) \n",
    "history = autoencoder.fit(X_train, X_train, epochs=20, batch_size=500, shuffle=False, verbose=1, validation_split=0.1)\n",
    "pu.plot_loss(history, title = 'model loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### evaluate the model on the training set\n",
    "\n",
    "prediction_train = autoencoder.predict(X_train)\n",
    "mse_train = aeu.mseTop10Raw(X_train, prediction_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot the global MSE trend\n",
    "\n",
    "pu.plot_mse(mse_train, rmlargest=0.005)\n",
    "(mean,std) = pu.plot_mse(mse_train, doplot=False, rmlargest=0.005)\n",
    "print('mean mse: {}'.format(mean))\n",
    "print('std mse: {}'.format(std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### impose a mse upper boundary and plot random examples of passing and failing histograms\n",
    "# note: at this point, only the training set is considered!\n",
    "# for a test set: see cell below.\n",
    "\n",
    "cutvalue = mean + 3*std\n",
    "print('The mse threshold is: '+str(cutvalue))\n",
    "goodindices = np.arange(0,len(mse_train))[mse_train<cutvalue]\n",
    "badindices = np.arange(0,len(mse_train))[mse_train>cutvalue]\n",
    "\n",
    "print('Number of passing histograms: '+str(len(goodindices)))\n",
    "print('Number of failing histograms: '+str(len(badindices)))\n",
    "\n",
    "nplot = 5\n",
    "print('examples of good histograms and reconstruction:')\n",
    "randint = np.random.choice(goodindices,size=nplot,replace=False)\n",
    "for i in randint: \n",
    "    histlist = [X_train[int(i),:],prediction_train[int(i),:]]\n",
    "    labellist = ['data','reconstruction']\n",
    "    colorlist = ['black','blue']\n",
    "    pu.plot_hists(histlist,colorlist=colorlist,labellist=labellist)\n",
    "    plt.show()\n",
    "\n",
    "print('examples of bad histograms and reconstruction:')\n",
    "randint = np.random.choice(badindices,size=nplot,replace=False)\n",
    "for i in randint:\n",
    "    histlist = [X_train[int(i),:],prediction_train[int(i),:]]\n",
    "    labellist = ['data','reconstruction']\n",
    "    colorlist = ['black','blue']\n",
    "    pu.plot_hists(histlist,colorlist=colorlist,labellist=labellist)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get a test set and evaluate the model\n",
    "\n",
    "goodrunsls = { \"297056\":[[-1]],\n",
    "                \"297177\":[[-1]],\n",
    "                \"301449\":[[-1]] \n",
    "             }\n",
    "badrunsls = {\n",
    "                \"297287\":[[-1]],\n",
    "                \"297288\":[[-1]],\n",
    "                \"297289\":[[-1]],\n",
    "                \"299316\":[[-1]],\n",
    "                \"299317\":[[-1]],\n",
    "                \"299318\":[[-1]],\n",
    "                \"299324\":[[-1]],\n",
    "            }\n",
    "\n",
    "# re-read the dataframe\n",
    "# (in case the selections are different than for the training set)\n",
    "dloader = DataLoader.DataLoader()\n",
    "df = dloader.get_dataframe_from_file( os.path.join(datadir, filename) )\n",
    "df = dfu.select_dcson(df)\n",
    "df = dfu.select_highstat(df,entries_to_bins_ratio=100)\n",
    "\n",
    "# good histograms option 1: predefined runs/lumisections\n",
    "#X_test_good = hu.preparedatafromdf( dfu.select_runsls(df,goodrunsls),donormalize=True )\n",
    "# good histograms option 2: averages of total set\n",
    "X_test_good = hu.averagehists( hu.preparedatafromdf(df, donormalize=True), 15 )\n",
    "# bad histograms: predefined runs/lumisections\n",
    "(X_test_bad, runnbs_bad,lsnbs_bad) = hu.preparedatafromdf( \n",
    "                                    dfu.select_runsls(df,badrunsls),\n",
    "                                    donormalize=True,\n",
    "                                    returnrunls = True )\n",
    "print('shape of good test set: {}'.format(X_test_good.shape))\n",
    "print('shape of bad test set: {}'.format(X_test_bad.shape))\n",
    "\n",
    "pu.plot_sets([X_test_good,X_test_bad],colorlist=['b','r'],\n",
    "             labellist=['Histograms in test set labeled \"good\"','Histograms in test set labeled \"bad\"'])\n",
    "plt.show()\n",
    "\n",
    "prediction_test_good = autoencoder.predict(X_test_good)\n",
    "mse_test_good = aeu.mseTopNRaw(X_test_good, prediction_test_good, n=10 )\n",
    "prediction_test_bad = autoencoder.predict(X_test_bad)\n",
    "mse_test_bad = aeu.mseTopNRaw(X_test_bad, prediction_test_bad, n=10 )\n",
    "\n",
    "print('average mse on good set: '+str(np.mean(mse_test_good)))\n",
    "print('average mse on bad set: '+str(np.mean(mse_test_bad)))\n",
    "\n",
    "nplot = 10\n",
    "print('examples of good histograms and reconstruction:')\n",
    "randint = np.random.choice(np.arange(len(X_test_good)),size=nplot,replace=False)\n",
    "for i in randint: \n",
    "    histlist = [X_test_good[int(i),:],prediction_test_good[int(i),:]]\n",
    "    labellist = ['data','reconstruction']\n",
    "    colorlist = ['black','blue']\n",
    "    pu.plot_hists(histlist,colorlist=colorlist,labellist=labellist)\n",
    "    plt.show()\n",
    "\n",
    "print('examples of bad histograms and reconstruction:')\n",
    "randint = np.random.choice(np.arange(len(X_test_bad)),size=nplot,replace=False)\n",
    "for i in randint:\n",
    "    histlist = [X_test_bad[int(i),:],prediction_test_bad[int(i),:]]\n",
    "    labellist = ['data','reconstruction']\n",
    "    colorlist = ['black','blue']\n",
    "    pu.plot_hists(histlist,colorlist=colorlist,labellist=labellist)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### use artificial data to assess the model performance\n",
    "\n",
    "(goodhists,_,_) = gdu.upsample_hist_set( X_test_good, ntarget=5e3, fourierstdfactor=20., doplot=True )\n",
    "(badhists,_,_) = gdu.upsample_hist_set( X_test_bad, ntarget=5e3, fourierstdfactor=20., doplot=True )\n",
    "print('number of good histograms: '+str(len(goodhists)))\n",
    "print('number of bad histograms: '+str(len(badhists)))\n",
    "\n",
    "validation_data = np.vstack((goodhists,badhists))\n",
    "labels = np.hstack((np.zeros(len(goodhists)),np.ones(len(badhists))))\n",
    "prediction = autoencoder.predict(validation_data)\n",
    "mse = aeu.mseTopNRaw(validation_data, prediction, n=10 )\n",
    "shuffled_indices = np.arange(len(validation_data))\n",
    "_ = np.random.shuffle(shuffled_indices)\n",
    "validation_data = validation_data[shuffled_indices]\n",
    "labels = labels[shuffled_indices]\n",
    "prediction = prediction[shuffled_indices]\n",
    "mse = mse[shuffled_indices]\n",
    "\n",
    "# distribution of output scores\n",
    "pu.plot_score_dist(mse, labels, \n",
    "                   siglabel='anomalous', sigcolor='r',\n",
    "                   bcklabel='good', bckcolor='g',\n",
    "                   nbins=200, normalize=True)\n",
    "print('minimum mse on bad set: {}'.format(np.amin(mse[np.where(labels==1)])))\n",
    "print('maximum mse on good set: {}'.format(np.amax(mse[np.where(labels==0)])))\n",
    "# classical ROC curve: signal efficiency (good data marked as good) vs background efficiency (bad data marked as good)\n",
    "auc = aeu.get_roc(mse, labels, npoints=500, bootstrap_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### continution of previous cell: choose wp and plot confusion matrix\n",
    "\n",
    "aeu.get_confusion_matrix_from_hists( validation_data, labels, prediction, msewp='maxauc' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot some histograms in the bad test set with their reconstruction\n",
    "\n",
    "inds = np.random.choice( np.arange(len(lsnbs_bad)), 10, replace=False )\n",
    "for i in inds:\n",
    "    runnb = runnbs_bad[i]\n",
    "    lsnb = lsnbs_bad[i]\n",
    "    histogram = X_test_bad[i:i+1,:]\n",
    "    reco = autoencoder.predict(histogram)\n",
    "    mse = aeu.mseTopNRaw(histogram, reco, n=10 )\n",
    "    pu.plot_sets([histogram,reco],\n",
    "                    labellist=['hist {}/{}'.format(runnb,lsnb),'reco'],\n",
    "                    colorlist=['black','red'],\n",
    "                    )\n",
    "    plt.show()\n",
    "    print('MSE: {}'.format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot some histograms in the good test set with their reconstruction\n",
    "# note: depends on whether the good test set was obtained from real lumisections,\n",
    "#       or from averages from entire set.\n",
    "\n",
    "inds = np.random.choice( np.arange(len(X_test_good)), 10, replace=False )\n",
    "for i in inds:\n",
    "    try:\n",
    "        runnb = runnbs_good[i]\n",
    "        lsnb = lsnbs_good[i]\n",
    "        histlabel = 'hist {}/{}'.format(runnb,lsnb)\n",
    "    except:\n",
    "        runnb = 0\n",
    "        lsnb = 0\n",
    "        histlabel = 'hist (artificial)'\n",
    "    histogram = X_test_good[i:i+1,:]\n",
    "    reco = autoencoder.predict(histogram)\n",
    "    mse = aeu.mseTopNRaw(histogram, reco, n=10 )\n",
    "    pu.plot_sets([histogram,reco],\n",
    "                    labellist=[histlabel,'reco'],\n",
    "                    colorlist=['black','red'],\n",
    "                    )\n",
    "    plt.show()\n",
    "    print('MSE: {}'.format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
