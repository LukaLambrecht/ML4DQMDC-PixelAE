{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "tested-speech",
   "metadata": {},
   "source": [
    "**A collection of useful basic functions for reading and processing the input csv files.**  \n",
    "\n",
    "Functionality includes:\n",
    "- reading the raw input csv files and producing more manageable csv files (grouped per histogram type).\n",
    "- reading csv files into pandas dataframes and writing pandas dataframes back to csv files.\n",
    "\n",
    "**Note: the functionality of these utils has been absorbed into the DataLoader class, which is now the recommended way to read the data!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-stability",
   "metadata": {},
   "outputs": [],
   "source": [
    "### imports\n",
    "\n",
    "# external modules\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import importlib\n",
    "\n",
    "# local modules\n",
    "import dataframe_utils as dfu\n",
    "importlib.reload(dfu)\n",
    "from notebook_utils.notebook_to_script import save_notebook_as_script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charitable-living",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_dirs(year='2017', eras=[], dim=1):\n",
    "    ### yield all data directories\n",
    "    # note that the location of the data is hard-coded;\n",
    "    # this function might break for newer or later reprocessings of the data.\n",
    "    # - year is a string, either '2017' or '2018'\n",
    "    # - era is a list containing a selection of era names\n",
    "    #   (default empty list = all eras)\n",
    "    # - dim is either 1 or 2 (for 1D or 2D plots)\n",
    "    if(year=='2017' and len(eras)==0): eras = ['B','C','D','E','F']\n",
    "    if(year=='2018' and len(eras)==0): eras = ['A','B','C','D']\n",
    "    basedir = '/eos/project/c/cmsml4dc/ML_2020/UL'+year+'_Data/'\n",
    "    for era in eras:\n",
    "        eradir = basedir+'DF'+year+era+'_'+str(dim)+'D_Complete'\n",
    "        if not os.path.exists(eradir):\n",
    "            print('ERROR in csv_utils.py / get_data_dirs: requested directory {}'.format(eradir)\n",
    "                  +' does not seem to exist, skipping it and continuing...')\n",
    "        else: yield eradir\n",
    "\n",
    "def get_csv_files(inputdir):\n",
    "    ### yields paths to all csv files in input directory\n",
    "    # note that the output paths consist of input_dir/filename\n",
    "    # this function is only meant for 1-level down searching,\n",
    "    # i.e. the .csv files listed directly under input_dir.\n",
    "    if not os.path.exists(inputdir):\n",
    "        raise Exception('ERROR in csv_utils.py / get_csv_files: input directory {}'.format(inputdir)\n",
    "                       +' does not seem to exist.')\n",
    "    for el in os.listdir(inputdir):\n",
    "        if el[-4:]=='.csv':\n",
    "            yield os.path.join(inputdir,el)\n",
    "\n",
    "def sort_filenames(filelist):\n",
    "    ### sort filenames in numerical order (e.g. 2 before 10)\n",
    "    # note that the number is supposed to be in ..._<number>.<extension> format\n",
    "    nlist = []\n",
    "    for f in filelist:\n",
    "        temp = f.rsplit('.',1)[0]\n",
    "        temp = temp[temp.rfind('_')+1:]\n",
    "        nlist.append(int(temp))\n",
    "    return [f for _,f in sorted(zip(nlist,filelist))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-alberta",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(csv_file):\n",
    "    ### read csv file into pandas dataframe\n",
    "    # csv_file is the path to the csv file to be read\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df.sort_values(by=['fromrun','fromlumi'],inplace=True)\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    return df\n",
    "\n",
    "def write_csv(dataframe,csvfilename):\n",
    "    ### write a dataframe to a csv file\n",
    "    # note: just a wrapper for builtin dataframe.to_csv\n",
    "    dataframe.to_csv(csvfilename)\n",
    "\n",
    "def read_and_merge_csv(csv_files, histnames=[], runnbs=[]):\n",
    "    ### read and merge list of csv files into a single df\n",
    "    # csv_files is a list of paths to files to merge into a df\n",
    "    # histnames is a list of the types of histograms to keep (default: all)\n",
    "    # runnbs is a list of run numbers to keep (default: all)\n",
    "    dflist = []\n",
    "    print('INFO in csv_utils.py / read_and_merge_csv:'\n",
    "          +' reading and merging {} csv files...'.format(len(csv_files)))\n",
    "    for i,f in enumerate(csv_files):\n",
    "        print('  - now processing file {} of {}...'.format(i+1,len(csv_files)))\n",
    "        dffile = read_csv(f)\n",
    "        if len(histnames)>0: \n",
    "            dffile = dfu.select_histnames(dffile,histnames)\n",
    "        if len(runnbs)>0:\n",
    "            dffile = dfu.select_runs(dffile,runnbs)\n",
    "        dflist.append(dffile)\n",
    "    df = pd.concat(dflist,ignore_index=True)\n",
    "    df.sort_values(by=['fromrun','fromlumi'],inplace=True)\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    print('INFO in csv_utils.py / read_and_merge_csv: merged {} csv files.'.format(len(csv_files)))\n",
    "    return df\n",
    "\n",
    "\n",
    "def write_skimmed_csv(histnames, year, eras=['all'], dim=1):\n",
    "    ### read all available data for a given year/era and make a file per histogram type\n",
    "    # input arguments:\n",
    "    # - histnames: list of histogram names for which to make a separate file\n",
    "    # - year: data-taking year (in string format)\n",
    "    # - eras: data-taking eras for which to make a separate file (in string format)\n",
    "    #         use 'all' to make a file with all eras merged, i.e. a full data taking year\n",
    "    # - dim: dimension of histograms (1 or 2), needed to retrieve the correct folder containing input files\n",
    "    # output:\n",
    "    # - one csv file per year/era and per histogram type\n",
    "    # note: this function can take quite a while to run!\n",
    "    \n",
    "    for era in eras:\n",
    "        thiseras = [era]\n",
    "        erasuffix = era\n",
    "        if era=='all': \n",
    "            thiseras = []\n",
    "            erasuffix = ''\n",
    "        datadirs = list(get_data_dirs(year=year,eras=thiseras,dim=dim))\n",
    "        csvfiles = []\n",
    "        for datadir in datadirs:\n",
    "            csvfiles += sort_filenames(list(get_csv_files(datadir)))\n",
    "        # read histograms into df\n",
    "        temp = read_and_merge_csv(csvfiles,histnames=histnames)\n",
    "        # write df to files\n",
    "        for histname in histnames:\n",
    "            seldf = dfu.select_histnames(temp,[histname])\n",
    "            histname = histname.replace(' ','_')\n",
    "            seldf.to_csv('DF'+year+erasuffix+'_'+histname+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noted-kinase",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_notebook_as_script( 'csv_utils.ipynb' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "billion-package",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
